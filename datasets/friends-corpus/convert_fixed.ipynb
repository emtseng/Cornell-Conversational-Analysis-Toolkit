{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_YNRDvb3etb"
   },
   "source": [
    "# Converting the Friends dataset into ConvoKit format\n",
    "\n",
    "This notebook describes how we converted the Friends dataset (https://github.com/emorynlp/character-mining) into a Corpus with ConvoKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wp3WIlBN4D7l",
    "outputId": "d175f9db-6bab-416b-d2d1-b98b1af1fd51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: convokit in /usr/local/lib/python3.7/site-packages (2.0.11)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/site-packages (from convokit) (1.3.1)\n",
      "Requirement already satisfied: spacy==2.0.12 in /usr/local/lib/python3.7/site-packages (from convokit) (2.0.12)\n",
      "Requirement already satisfied: msgpack-numpy==0.4.3.2 in /usr/local/lib/python3.7/site-packages (from convokit) (0.4.3.2)\n",
      "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.7/site-packages (from convokit) (3.4.5)\n",
      "Requirement already satisfied: dill==0.2.9 in /usr/local/lib/python3.7/site-packages (from convokit) (0.2.9)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from convokit) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/site-packages (from convokit) (0.21.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/site-packages (from convokit) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from scipy>=1.1.0->convokit) (1.17.2)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (0.28.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (1.31.2)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (6.10.3)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (0.9.6)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (1.0.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (1.35)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (2.22.0)\n",
      "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.7/site-packages (from spacy==2.0.12->convokit) (2017.4.5)\n",
      "Requirement already satisfied: msgpack>=0.3.0 in /usr/local/lib/python3.7/site-packages (from msgpack-numpy==0.4.3.2->convokit) (0.6.1)\n",
      "Requirement already satisfied: six in /Users/emilytseng/Library/Python/3.7/lib/python/site-packages (from nltk>=3.4->convokit) (1.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn>=0.20.0->convokit) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas>=0.23.4->convokit) (2019.2)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit) (0.9.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit) (4.35.0)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit) (1.10.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit) (1.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->convokit) (41.0.1)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install convokit\n",
    "# !python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXk4Biep3xHH"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, User, Utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmw72j5J44E4"
   },
   "source": [
    "## The Friends Dataset\n",
    "\n",
    "The original dataset (https://github.com/emorynlp/character-mining) contains a set of 10 JSON files, each of which represents a complete transcript of 1 season of <i>Friends</i>. Since the data are available in JSON format from this GitHub repo, we download the raw data directly using the `requests` module. You will not need to download raw data files to use this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxhlL6aNCvxr"
   },
   "source": [
    "## Generating user information\n",
    "Since our dataset doesn't have any existing user information, we extract speaker information from the conversation. For each user, we collect the episode in which he/she first appears and guess his/her gender based on the name using the gender_guesser module.\n",
    "\n",
    "Users are indexed by their name, which is a `<str>`. For each user, we create an object with:\n",
    "\n",
    "- <b>first_appearance:</b> the episode in which he or she first appeared\n",
    "- <b>gender:</b> the character's gender, as defined by the `gender_guesser` module's guess of his/her name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "sw_7_7YJMIWp",
    "outputId": "db9ad417-6448-4075-fa0b-163126f2b706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gender_guesser in /usr/local/lib/python3.7/site-packages (0.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip3 install gender_guesser\n",
    "import gender_guesser.detector as gender\n",
    "d = gender.Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mjNZT57Qv7Vd",
    "outputId": "cd19eef4-c487-4fd3-a336-705e284c0e32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "users = {}\n",
    "for i in tqdm(range(1,11)):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        speaker_list = utterance['speakers']\n",
    "        for speaker in speaker_list:\n",
    "          if speaker not in users:\n",
    "            users[speaker] = {'first_appearance': episode['episode_id'], 'gender': d.get_gender(speaker.split()[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJqo7WSSCua1"
   },
   "source": [
    "Sanity-checking the user data, we should see the correct genders assigned to the 6 friends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YeKBCPZqCMeH",
    "outputId": "3d8d81bf-36f4-4c7f-8424-437b32bbca56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users in the data = 700/700\n",
      "Monica Geller object:  {'first_appearance': 's01_e01', 'gender': 'female'}\n",
      "Joey Tribbiani object:  {'first_appearance': 's01_e01', 'gender': 'male'}\n",
      "Chandler Bing object:  {'first_appearance': 's01_e01', 'gender': 'mostly_male'}\n",
      "Phoebe Buffay object:  {'first_appearance': 's01_e01', 'gender': 'female'}\n",
      "Ross Geller object:  {'first_appearance': 's01_e01', 'gender': 'male'}\n",
      "Rachel Green object:  {'first_appearance': 's01_e01', 'gender': 'female'}\n"
     ]
    }
   ],
   "source": [
    "print(\"number of users in the data = {}/700\".format(len(users)))\n",
    "print(\"Monica Geller object: \", users[\"Monica Geller\"])\n",
    "print(\"Joey Tribbiani object: \", users[\"Joey Tribbiani\"])\n",
    "print(\"Chandler Bing object: \", users[\"Chandler Bing\"])\n",
    "print(\"Phoebe Buffay object: \", users[\"Phoebe Buffay\"])\n",
    "print(\"Ross Geller object: \", users[\"Ross Geller\"])\n",
    "print(\"Rachel Green object: \", users[\"Rachel Green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Csa06wuFh8U"
   },
   "source": [
    "We then create a User object for each unique character in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude meta data in User such as first_appearnce and gender or general use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs7QjJJJFg2S"
   },
   "outputs": [],
   "source": [
    "corpus_users = {k: User(name=k) for k,v in users.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cfMxU1u_GJD7",
    "outputId": "9608f357-a05d-4305-bc57-f2468f9d119e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monica Geller\n",
      "{'first_appearance': 's01_e01', 'gender': 'female'}\n"
     ]
    }
   ],
   "source": [
    "print(corpus_users['Monica Geller'].name)\n",
    "print(corpus_users['Monica Geller'].meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tJ_9BMXFygP"
   },
   "source": [
    "## Generating Utterances\n",
    "\n",
    "We then loop through the data to generate a list of all utterances in the series. To align with the Utterance schema ConvoKit expects, we construct for each utterance:\n",
    "\n",
    "- **id:** index of the utterance\n",
    "\n",
    "- **user:** the user who authored the utterance; the speaker in our case\n",
    "\n",
    "- **root:** id of the conversation root of the utterance; the first utterance in the scene, in our case\n",
    "\n",
    "- **reply_to:** id of the utterance to which this utterance replies to; None if the utterance is not a reply.\n",
    "\n",
    "- **timestamp:** time of the utterance (None for us -- the dataset does not contain this information)\n",
    "\n",
    "- **text:** textual content of the utterance\n",
    "\n",
    "We also pull in the following metadata including:\n",
    "- **tokens** a tokenized representation of the text (handy for sentence separation)\n",
    "-**character_entities** available for some but not all utterances; `None` if unavailable. These are intended to identify who the user is speaking to and/or about.\n",
    "-**emotion** emotion labels for each token. Available for some but not all utterances; `None` if unavailable. \n",
    "-**caption**  available for some but not all utterances; `None` if unavailable. This contains the begin time, end time, and text sans punctuation. Only available for seasons 6-9.\n",
    "-**transcript_with_note**  a version of the text with an action note (e.g. \"(to Ross) Hand me the coffee\" vs. \"Hand me the coffee\"). Available for some but not all utterances; `None` if unavailable.\n",
    "-**token_with_note** a tokenized representation of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MDgFZjF6GN3O",
    "outputId": "3a963fc3-cba2-4a3a-b932-cc9526568439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "all_utterances = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(1,11)):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      \n",
    "      root = utterances[0] #set the root as the first utterance in the scene for now\n",
    "      \n",
    "      prev_utt = None\n",
    "\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        \n",
    "        speaker = utterance['speakers']\n",
    "\n",
    "        # Add meta       \n",
    "        meta = {\n",
    "            'tokens': utterance.get('tokens'),\n",
    "            'character_entities': utterance.get('character_entities'),\n",
    "            'emotion': utterance.get('emotion'),\n",
    "            'caption': utterance.get('caption'),\n",
    "            'transcript_with_note': utterance.get('transcript_with_note'),\n",
    "            'tokens_with_note': utterance.get('tokens_with_note')\n",
    "        }\n",
    "        \n",
    "        # Create the Utterance, including meta\n",
    "        all_utterances[utterance['utterance_id']] = Utterance(\n",
    "            id=utterance['utterance_id'],\n",
    "            user=corpus_users[speaker[0]] if len(speaker) != 0 else None, # Check if people speaking or just scripts\n",
    "            root=root['utterance_id'],\n",
    "            reply_to=prev_utt,\n",
    "            timestamp=None,\n",
    "            text=utterance['transcript'],\n",
    "            meta=meta\n",
    "        )\n",
    "        \n",
    "        # Get the prev_utt for the next iteration\n",
    "        prev_utt = utterance['utterance_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmVQJYBiI1aY",
    "outputId": "5fe98756-0ba8-4052-a288-59117417cac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This corpus has 61338/61309 utterances\n"
     ]
    }
   ],
   "source": [
    "print(\"This corpus has {}/61309 utterances\".format(len(all_utterances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NkOm5qDdZYRQ",
    "outputId": "ea4e4a62-1260-4179-8e41-0450404fe3e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utterance({'id': 's01_e18_c05_u021', 'user': User([('name', 'Ross Geller')]), 'root': 's01_e18_c05_u001', 'reply_to': 's01_e18_c05_u020', 'timestamp': None, 'text': 'Alright.', 'meta': {'tokens': [['Alright', '.']], 'character_entities': [[]], 'emotion': ['Neutral', ['Neutral', 'Neutral', 'Neutral', 'Neutral']], 'caption': None, 'transcript_with_note': None, 'tokens_with_note': None}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_utterances['s01_e18_c05_u021']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjb5fkwmN5Ma"
   },
   "source": [
    "## Creating the corpus from a list of utterances\n",
    "\n",
    "We now create the corpus from our dict of utterances. Note, we are are allowing convokit to create conversations IDs automatically after loading the utterances list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0C_xjYMfOKVL"
   },
   "outputs": [],
   "source": [
    "utterance_list = [utt for k, utt in all_utterances.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVyGuspKOU7E"
   },
   "outputs": [],
   "source": [
    "friends_corpus = Corpus(utterances=utterance_list, version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add meta data to automatically generated conversations and modify IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversations = {}\n",
    "for conv in friends_corpus.get_conversation_ids():\n",
    "  new_conversations[conv[:11]] = friends_corpus.conversations[conv]\n",
    "  new_conversations[conv[:11]].meta = {'season': conv.split('_')[0], 'episode': conv.split('_')[1], 'scene': conv.split('_')[2]}\n",
    "friends_corpus.conversations = new_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(friends_corpus.conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UW5uEDZIcjWO"
   },
   "source": [
    "Sanity checks for the number of conversations in the dataset and the first 5 conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oCQcxnu1OZXv",
    "outputId": "d6c78d98-9a75-4f64-a1e0-4ab8634e023b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of conversations in the dataset=3099\n"
     ]
    }
   ],
   "source": [
    "print(\"number of conversations in the dataset={}\".format(len(friends_corpus.get_conversation_ids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Uypy9F-Vx0kM",
    "outputId": "7d7dcf7c-40cf-4366-c15d-df2d96397877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample conversation 0:\n",
      "['s01_e01_c01_u001', 's01_e01_c01_u002', 's01_e01_c01_u003', 's01_e01_c01_u004', 's01_e01_c01_u006', 's01_e01_c01_u007', 's01_e01_c01_u008', 's01_e01_c01_u010', 's01_e01_c01_u011', 's01_e01_c01_u012', 's01_e01_c01_u013', 's01_e01_c01_u014', 's01_e01_c01_u015', 's01_e01_c01_u016', 's01_e01_c01_u017', 's01_e01_c01_u018', 's01_e01_c01_u019', 's01_e01_c01_u021', 's01_e01_c01_u022', 's01_e01_c01_u023', 's01_e01_c01_u024', 's01_e01_c01_u025', 's01_e01_c01_u026', 's01_e01_c01_u027', 's01_e01_c01_u028', 's01_e01_c01_u029', 's01_e01_c01_u030', 's01_e01_c01_u031', 's01_e01_c01_u032', 's01_e01_c01_u033', 's01_e01_c01_u034', 's01_e01_c01_u035', 's01_e01_c01_u036', 's01_e01_c01_u037', 's01_e01_c01_u038', 's01_e01_c01_u039', 's01_e01_c01_u040', 's01_e01_c01_u041', 's01_e01_c01_u042', 's01_e01_c01_u044', 's01_e01_c01_u045', 's01_e01_c01_u047', 's01_e01_c01_u048', 's01_e01_c01_u049', 's01_e01_c01_u050', 's01_e01_c01_u051', 's01_e01_c01_u052', 's01_e01_c01_u053', 's01_e01_c01_u055', 's01_e01_c01_u056', 's01_e01_c01_u057', 's01_e01_c01_u058']\n",
      "sample conversation 1:\n",
      "['s01_e01_c02_u001', 's01_e01_c02_u002', 's01_e01_c02_u003', 's01_e01_c02_u004', 's01_e01_c02_u006', 's01_e01_c02_u007', 's01_e01_c02_u008', 's01_e01_c02_u009', 's01_e01_c02_u011', 's01_e01_c02_u012', 's01_e01_c02_u013', 's01_e01_c02_u014', 's01_e01_c02_u015', 's01_e01_c02_u017', 's01_e01_c02_u018', 's01_e01_c02_u019', 's01_e01_c02_u020', 's01_e01_c02_u021', 's01_e01_c02_u022', 's01_e01_c02_u023', 's01_e01_c02_u024', 's01_e01_c02_u026', 's01_e01_c02_u027', 's01_e01_c02_u028', 's01_e01_c02_u029', 's01_e01_c02_u030', 's01_e01_c02_u031', 's01_e01_c02_u032', 's01_e01_c02_u033', 's01_e01_c02_u034', 's01_e01_c02_u035', 's01_e01_c02_u036', 's01_e01_c02_u037', 's01_e01_c02_u038', 's01_e01_c02_u039', 's01_e01_c02_u040', 's01_e01_c02_u041', 's01_e01_c02_u043', 's01_e01_c02_u044', 's01_e01_c02_u045', 's01_e01_c02_u046', 's01_e01_c02_u047', 's01_e01_c02_u048', 's01_e01_c02_u049', 's01_e01_c02_u051', 's01_e01_c02_u052', 's01_e01_c02_u053', 's01_e01_c02_u054', 's01_e01_c02_u055', 's01_e01_c02_u056', 's01_e01_c02_u057', 's01_e01_c02_u058', 's01_e01_c02_u059', 's01_e01_c02_u060', 's01_e01_c02_u061', 's01_e01_c02_u062']\n",
      "sample conversation 2:\n",
      "['s01_e01_c03_u001']\n",
      "sample conversation 3:\n",
      "['s01_e01_c04_u001', 's01_e01_c04_u003', 's01_e01_c04_u004', 's01_e01_c04_u005', 's01_e01_c04_u006', 's01_e01_c04_u007', 's01_e01_c04_u008', 's01_e01_c04_u010', 's01_e01_c04_u011', 's01_e01_c04_u012', 's01_e01_c04_u013', 's01_e01_c04_u014', 's01_e01_c04_u015', 's01_e01_c04_u016', 's01_e01_c04_u017', 's01_e01_c04_u018', 's01_e01_c04_u019']\n",
      "sample conversation 4:\n",
      "['s01_e01_c05_u001', 's01_e01_c05_u002', 's01_e01_c05_u003', 's01_e01_c05_u004', 's01_e01_c05_u005', 's01_e01_c05_u006', 's01_e01_c05_u007', 's01_e01_c05_u008', 's01_e01_c05_u009']\n"
     ]
    }
   ],
   "source": [
    "convo_ids = friends_corpus.get_conversation_ids()\n",
    "for i, convo_idx in enumerate(convo_ids[0:5]):\n",
    "    print(\"sample conversation {}:\".format(i))\n",
    "    print(friends_corpus.get_conversation(convo_idx).get_utterance_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NAHTbGQxcor3"
   },
   "source": [
    "Summary stats for the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "G0pyZSmWW9_1",
    "outputId": "e8e9d98a-c07b-4664-a048-4322ff105c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 699\n",
      "Number of Utterances: 61338\n",
      "Number of Conversations: 3099\n"
     ]
    }
   ],
   "source": [
    "friends_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0WxYF6jbY5l"
   },
   "source": [
    "## Adding corpus-level metadata\n",
    "\n",
    "We add the name of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oGMAvEza5hL"
   },
   "outputs": [],
   "source": [
    "friends_corpus.meta['name'] = 'Friends Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiUf8K6hTNjV"
   },
   "source": [
    "# Create the corpus dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaM2QdLJ4kPl"
   },
   "source": [
    "If working in a locally mounted notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtD1v0Jo4nf7"
   },
   "outputs": [],
   "source": [
    "friends_corpus.dump(\"friends-corpus\", base_path = \"/Users/emilytseng/Cornell-Conversational-Analysis-Toolkit/datasets/friends-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uygI-2aU2PKn"
   },
   "source": [
    "If working in Google Colab, first mount your Google Drive, then dump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "aMcBSeS2xumI",
    "outputId": "bb123206-1a9d-47e9-e085-f3c4b8744d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "import google\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1TGJ37nzKUh"
   },
   "outputs": [],
   "source": [
    "friends_corpus.dump(\"friends-corpus\", base_path = \"gdrive/My Drive/F19-CS6742/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aN2CraqRaUYb"
   },
   "outputs": [],
   "source": [
    "with ZipFile(\"gdrive/My Drive/CS6742/friends-corpus.zip\", 'w') as zip_f:\n",
    "  for fname in os.listdir(\"gdrive/My Drive/CS6742/friends-corpus\"):\n",
    "    zip_f.write(\"gdrive/My Drive/CS6742/friends-corpus/\"+fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the corpus dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading friends-corpus to /Users/emilytseng/.convokit/downloads/friends-corpus\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'friends-corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-95f23e28867a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconvokit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"friends-corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/convokit/util.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(name, verbose, data_dir, use_newest_version)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdownload_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotif_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownloadeds_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetURLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mdownload_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownloadeds_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'friends-corpus'"
     ]
    }
   ],
   "source": [
    "from convokit import download\n",
    "test_corpus = Corpus(filename=download(\"friends-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convert-et397.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
